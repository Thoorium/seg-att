{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "import random\n",
    "\n",
    "from IPython import display\n",
    "from skimage.draw import random_shapes, rectangle, polygon, circle\n",
    "\n",
    "from attention_augmented_conv import augmented_conv2d\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE_SIZE = 128\n",
    "CHANNELS = 1\n",
    "IMAGE_COUNT = 300\n",
    "NUM_CLASSES = 1 + 1 # BG + Classes\n",
    "MAX_SHAPES = 3\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 150\n",
    "NUM_EXAMPLES_TO_GENERATE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_mask(size=(448, 448), max_shapes=3, show_result=False):\n",
    "    masks = []\n",
    "    while(len(masks) == 0):\n",
    "        image, labels = random_shapes(size, min_shapes=1, max_shapes=max_shapes,\n",
    "                                 min_size=size[0]/4, allow_overlap=False, multichannel=(CHANNELS == 3),\n",
    "                                     num_trials = 10)#, shape='triangle'\n",
    "\n",
    "        # Generate individual masks    \n",
    "        for i in range(0, len(labels)):\n",
    "            img= np.zeros(size, dtype=np.uint8)\n",
    "            class_id = 0\n",
    "\n",
    "            if(labels[i][0] == 'rectangle'):\n",
    "                continue\n",
    "                #rr, cc = rectangle((labels[i][1][0][0], labels[i][1][1][0]), (labels[i][1][0][1], labels[i][1][1][1]),\n",
    "                #           shape=img.shape)\n",
    "                #class_id = 1\n",
    "            if(labels[i][0] == 'circle'):\n",
    "                continue\n",
    "                #y = labels[i][1][0][1]- (labels[i][1][0][1] - labels[i][1][0][0]) / 2\n",
    "                #x = labels[i][1][1][1]-(labels[i][1][1][1] - labels[i][1][1][0]) / 2\n",
    "                #r = (labels[i][1][0][1] - labels[i][1][0][0]) / 2        \n",
    "                #rr, cc = circle(y, x, r, shape=img.shape)\n",
    "                #class_id = -1\n",
    "            if(labels[i][0] == 'triangle'):\n",
    "                x = (labels[i][1][1][0], labels[i][1][1][1] - (labels[i][1][1][1] - labels[i][1][1][0]) / 2, labels[i][1][1][1], labels[i][1][1][0])\n",
    "                y = (labels[i][1][0][1], labels[i][1][0][0], labels[i][1][0][1], labels[i][1][0][1])\n",
    "                rr, cc = polygon(y, x, shape=img.shape)  \n",
    "                class_id = 1\n",
    "\n",
    "            img[rr, cc] = class_id\n",
    "            masks.append(img)\n",
    "\n",
    "        if(len(masks) == 0):\n",
    "            continue\n",
    "        # Merge the masks\n",
    "        mask = np.zeros(size, dtype=np.uint8)\n",
    "        for i in range(0, len(masks)):\n",
    "            mask = np.add(mask, masks[i])\n",
    "\n",
    "        background = 1 - mask\n",
    "        final_mask = np.dstack((background, mask))\n",
    "\n",
    "        if(show_result):\n",
    "            print(labels)\n",
    "            fig=plt.figure(figsize=(8, 8))\n",
    "            fig.add_subplot(1, len(labels)+1, 1)\n",
    "            plt.imshow(image)\n",
    "            for i in range(0, len(labels)):    \n",
    "                fig.add_subplot(1, len(labels)+1, i+2)\n",
    "                plt.imshow(masks[i], cmap=\"Greys\")\n",
    "            plt.show()\n",
    "        return image, final_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(raw_image):\n",
    "    t = tf.convert_to_tensor(raw_image, np.float32)\n",
    "    #print(t.shape)\n",
    "    if(CHANNELS == 1):\n",
    "        t = tf.reshape(t, (SHAPE_SIZE, SHAPE_SIZE, CHANNELS,))\n",
    "    #t = (t - 127.5) / 127.5\n",
    "    #else: t = t / 255.0\n",
    "    t = t / 255.0\n",
    "    return t\n",
    "\n",
    "def preprocess_mask(raw_mask):\n",
    "    t = tf.convert_to_tensor(raw_mask, np.float32)\n",
    "    t = tf.reshape(t, (SHAPE_SIZE, SHAPE_SIZE, NUM_CLASSES,))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "masks = []\n",
    "for i in range(0, IMAGE_COUNT):\n",
    "    image, img_mask = generate_image_mask(size=(SHAPE_SIZE, SHAPE_SIZE), max_shapes=MAX_SHAPES)\n",
    "    images.append(preprocess_image(image))\n",
    "    masks.append(preprocess_mask(img_mask))\n",
    "    #masks.append(img_mask)\n",
    "    if((i / IMAGE_COUNT * 100.0) % 10 == 0):\n",
    "        print(i)\n",
    "# Display a sample image\n",
    "print(images[0].shape)\n",
    "if(CHANNELS == 1):\n",
    "    plt.imshow(images[0][:, :, 0], cmap='gray')\n",
    "else : plt.imshow(images[0])\n",
    "#print(masks[0][:,:, 0])\n",
    "#print(masks[0][:,:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_ds = tf.data.Dataset.from_tensor_slices(images)\n",
    "msk_ds = tf.data.Dataset.from_tensor_slices(masks)\n",
    "img_msk_ds = tf.data.Dataset.zip((img_ds, msk_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a shuffle buffer size as large as the dataset ensures that the data is\n",
    "# completely shuffled.\n",
    "#ds = img_msk_ds.apply(\n",
    "#  tf.data.experimental.shuffle_and_repeat(buffer_size=IMAGE_COUNT))\n",
    "#ds = ds.batch(BATCH_SIZE)\n",
    "#ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "#ds\n",
    "\n",
    "# Setting a shuffle buffer size as large as the dataset ensures that the data is\n",
    "# completely shuffled.\n",
    "ds = img_msk_ds.shuffle(buffer_size=IMAGE_COUNT)\n",
    "#ds = ds.repeat()\n",
    "ds = ds.batch(BATCH_SIZE)\n",
    "# `prefetch` lets the dataset fetch batches, in the background while the model is training.\n",
    "ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_segmentation_model(conv_size):\n",
    "    c = 32\n",
    "    model = tf.keras.Sequential()\n",
    "    max_depth = SHAPE_SIZE // c\n",
    "    print('Max depth:{}'.format(max_depth))\n",
    "    # DOWN    \n",
    "    for i in range(1, max_depth+1):\n",
    "        print(i)\n",
    "        cc = int(c * (i * 2))\n",
    "        model.add(layers.Conv2D(cc, conv_size, strides=(1, 1), padding='same', use_bias=False, input_shape=(SHAPE_SIZE,SHAPE_SIZE,CHANNELS)))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.LeakyReLU())\n",
    "\n",
    "        model.add(layers.MaxPool2D())\n",
    "        \n",
    "        # Making sure we don't end up into negative dimensions\n",
    "        if(model.output_shape[1] == 1):\n",
    "            print('True depth:{}'.format(i))\n",
    "            break\n",
    "            \n",
    "    \n",
    "    \n",
    "    # UP    \n",
    "    for i in range(max_depth+1, 1, -1):\n",
    "        cc = int(c * (i * 2))\n",
    "        model.add(layers.Conv2DTranspose(cc, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.LeakyReLU())\n",
    "        \n",
    "        if(model.output_shape[1] == SHAPE_SIZE):\n",
    "            break\n",
    "\n",
    "    model.add(layers.Conv2D(NUM_CLASSES, (1, 1), strides=(1, 1), padding='same', use_bias=False))\n",
    "    model.add(layers.Softmax())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentator1 = make_segmentation_model((2, 2))\n",
    "#tf.keras.Sequential(\n",
    "#    [\n",
    "#        tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(SHAPE_SIZE, SHAPE_SIZE, CHANNELS)),\n",
    "        #tf.keras.layers.AveragePooling2D(),\n",
    "        #tf.keras.layers.Dense(NUM_CLASSES),\n",
    "        #tf.keras.layers.Conv2D(NUM_CLASSES, (1, 1), strides=(1, 1), padding='same', use_bias=False),\n",
    "        #tf.keras.layers.Softmax()\n",
    "#    ]\n",
    "#)#make_segmentation_model((2, 2))\n",
    "segmentator2 = make_segmentation_model((3, 3))\n",
    "\n",
    "noise = tf.random.normal([1, SHAPE_SIZE, SHAPE_SIZE, CHANNELS])\n",
    "image_mask = segmentator1(noise, training=False)\n",
    "print(image_mask.shape)\n",
    "\n",
    "if(CHANNELS == 1):\n",
    "    plt.imshow(image_mask[0, :, :, 0], cmap='gray')\n",
    "else: plt.imshow(image_mask[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_mask2 = segmentator1(tf.reshape(tf.convert_to_tensor(images[0]), (1, SHAPE_SIZE, SHAPE_SIZE, CHANNELS)), training=False)\n",
    "print(image_mask2.shape)\n",
    "if(CHANNELS == 1):\n",
    "    plt.imshow(image_mask2[0, :, :, 0], cmap='gray')\n",
    "else: plt.imshow(image_mask2[0, :, :, 0])\n",
    "#segmentator1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_meta_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[SHAPE_SIZE, SHAPE_SIZE, NUM_CLASSES * 2]))\n",
    "    \n",
    "    #model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
    "    #model.add(layers.AveragePooling2D())\n",
    "    #model.add(layers.BatchNormalization())\n",
    "    #model.add(layers.LeakyReLU())\n",
    "    \n",
    "    #model.add(layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
    "    #model.add(layers.BatchNormalization())\n",
    "    #model.add(layers.LeakyReLU())\n",
    "    \n",
    "    #model.add(layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
    "    #model.add(layers.BatchNormalization())\n",
    "    #model.add(layers.LeakyReLU())\n",
    "    \n",
    "    #model.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.MaxPooling2D())\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())    \n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same', use_bias=False))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())   \n",
    "    \n",
    "    model.add(layers.Conv2D(NUM_CLASSES, (1, 1), strides=(1, 1), padding='same', use_bias=False))\n",
    "    #model.add(layers.Softmax())\n",
    "    model.add(layers.ReLU())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metanet = make_meta_model()\n",
    "timage = tf.reshape(tf.convert_to_tensor(images[0]), (1, SHAPE_SIZE, SHAPE_SIZE, CHANNELS))\n",
    "tfinal = tf.concat([image_mask, image_mask], -1)\n",
    "#print(tfinal.shape)\n",
    "decision = metanet(tfinal)\n",
    "print (decision.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This method returns a helper function to compute cross entropy loss\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def metanet_loss(truth, real_output, seg_output):\n",
    "    #real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    #seg_loss = cross_entropy(tf.zeros_like(seg_output), seg_output)\n",
    "    real_loss = cce(truth, real_output)\n",
    "    seg_loss = cce(truth, seg_output)\n",
    "    total_loss = real_loss + seg_loss\n",
    "    return total_loss\n",
    "\n",
    "def segmentator_loss(truth, seg_output):\n",
    "    #return cross_entropy(tf.ones_like(seg_output), seg_output)\n",
    "    return cce(truth, seg_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "meta_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './prototype_training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(segmentation_optimizer=segmentation_optimizer,\n",
    "                                 meta_optimizer=meta_optimizer,\n",
    "                                 segmentator1=segmentator1,\n",
    "                                 metanet=metanet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = SHAPE_SIZE\n",
    "# We will reuse this seed overtime (so it's easier)\n",
    "# to visualize progress in the animated GIF)\n",
    "#seed = tf.random.normal([NUM_EXAMPLES_TO_GENERATE, noise_dim, noise_dim, 1])\n",
    "seed = []\n",
    "seed_truth = []\n",
    "for i in range(0, NUM_EXAMPLES_TO_GENERATE):\n",
    "    img, truth = generate_image_mask(size=(SHAPE_SIZE, SHAPE_SIZE), max_shapes=MAX_SHAPES)\n",
    "    seed.append(preprocess_image(img))\n",
    "    seed_truth.append(preprocess_mask(truth))\n",
    "seed = tf.convert_to_tensor(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the use of `tf.function`\n",
    "# This annotation causes the function to be \"compiled\".\n",
    "@tf.function\n",
    "def train_step(images, masks):\n",
    "    #noise = tf.random.normal([BATCH_SIZE, noise_dim, noise_dim, 1])\n",
    "\n",
    "    with tf.GradientTape() as seg_tape1, tf.GradientTape() as seg_tape2, tf.GradientTape() as meta_tape:#\n",
    "        generated_masks1 = segmentator1(images, training=True)\n",
    "        generated_masks2 = segmentator2(images, training=True)\n",
    "\n",
    "        #real_output = metanet(tf.concat([masks, masks], -1), training=True)\n",
    "        seg_output = metanet(tf.concat([generated_masks1, generated_masks2], -1), training=True)\n",
    "\n",
    "        seg_loss1 = segmentator_loss(seg_output, generated_masks1)\n",
    "        seg_loss2 = segmentator_loss(seg_output, generated_masks2)\n",
    "        meta_loss = segmentator_loss(masks, seg_output)\n",
    "\n",
    "    gradients_of_segmentator1 = seg_tape1.gradient(seg_loss1, segmentator1.trainable_variables)\n",
    "    gradients_of_segmentator2 = seg_tape2.gradient(seg_loss2, segmentator2.trainable_variables)\n",
    "    gradients_of_metanet = meta_tape.gradient(meta_loss, metanet.trainable_variables)\n",
    "\n",
    "    segmentation_optimizer.apply_gradients(zip(gradients_of_segmentator1, segmentator1.trainable_variables))\n",
    "    segmentation_optimizer.apply_gradients(zip(gradients_of_segmentator2, segmentator2.trainable_variables))\n",
    "    meta_optimizer.apply_gradients(zip(gradients_of_metanet, metanet.trainable_variables))\n",
    "    return seg_loss1, seg_loss2#, meta_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch, mask_batch in dataset:\n",
    "            seg_loss1, seg_loss2 = train_step(image_batch, mask_batch)#, meta_loss\n",
    "\n",
    "        # Produce images for the GIF as we go\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_save_images(segmentator1, segmentator2,\n",
    "                                 epoch + 1,\n",
    "                                 seed)\n",
    "\n",
    "        # Save the model every 15 epochs\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "        print('Segmentation loss is {}, {}'.format(seg_loss1, seg_loss2))\n",
    "        #print('Meta loss is {}'.format(meta_loss))\n",
    "        #print(metanet.output_loss)\n",
    "\n",
    "    # Generate after the final epoch\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(segmentator1, segmentator2,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model1, model2, epoch, test_input):\n",
    "    # Notice `training` is set to False.\n",
    "    # This is so all layers run in inference mode (batchnorm).\n",
    "    predictions1 = model1(test_input, training=False)\n",
    "    predictions2 = model2(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(NUM_EXAMPLES_TO_GENERATE,NUM_EXAMPLES_TO_GENERATE))\n",
    "    offset = 1\n",
    "    for i in range(predictions1.shape[0]):\n",
    "        plt.subplot(NUM_EXAMPLES_TO_GENERATE, 4, i+offset)\n",
    "        plt.imshow(predictions1[i, :, :, 1], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        offset = offset + 1\n",
    "        plt.subplot(NUM_EXAMPLES_TO_GENERATE, 4, i+offset)\n",
    "        plt.imshow(predictions2[i, :, :, 1], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        offset = offset + 1\n",
    "        plt.subplot(NUM_EXAMPLES_TO_GENERATE, 4, i+offset)\n",
    "        plt.imshow(seed_truth[i][:, :, 1], cmap='gray')\n",
    "        plt.axis('off')\n",
    "        offset = offset + 1\n",
    "        plt.subplot(NUM_EXAMPLES_TO_GENERATE, 4, i+offset)\n",
    "        if(CHANNELS == 1):\n",
    "            plt.imshow(seed[i][:, :, 0], cmap='gray')\n",
    "        else: plt.imshow(seed[i])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.savefig('prototype_image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "train(ds, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anim_file = 'prototype.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "    filenames = glob.glob('prototype_image*.png')\n",
    "    filenames = sorted(filenames)\n",
    "    last = -1\n",
    "    for i,filename in enumerate(filenames):\n",
    "        #frame = 2*(i**0.5)\n",
    "        #if round(frame) > round(last):\n",
    "        #  last = frame\n",
    "        #else:«\n",
    "        #  continue\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "\n",
    "import IPython\n",
    "#if IPython.version_info > (6,2,0,''):\n",
    "display.Image(filename=anim_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
